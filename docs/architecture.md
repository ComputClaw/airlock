# Airlock Architecture

## Core Principle: Deterministic Execution

> **Same code + same source data = same numbers. Every time.**

This is the foundational rule of Airlock. All data fetching, aggregation, calculation, and report building runs as deterministic Python. The LLM is optional and strictly for presentation — summaries, conclusions, narrative insights. The data itself is never generated by an LLM.

Why this matters:
- Reports are auditable and reproducible
- Bugs are debuggable (re-run the same code, get the same result)
- LLM non-determinism is confined to a clearly separated layer
- Trust: stakeholders can verify numbers independently

---

## Overview

Airlock is a Python code execution service that sits between AI agents and authenticated infrastructure. It accepts code from agents, runs it in an isolated environment with injected secrets, and returns sanitized results via a polling API.

Users manage credentials and access through a **web UI**. Agents interact through a minimal **HTTP API** authenticated by **profile IDs**.

```
┌──────────────────────────────────────────────────────────────────┐
│                           User                                   │
│                                                                  │
│  Opens web UI at http://<airlock-host>:9090                      │
│  • Adds API credentials (stored encrypted)                       │
│  • Creates profiles (ark_...) — scoped access to credentials     │
│  • Sets expiration, views execution history & stats              │
└──────────────────┬───────────────────────────────────────────────┘
                   │ Browser
┌──────────────────▼───────────────────────────────────────────────┐
│                     Airlock Server                                │
│                     (FastAPI — single container)                  │
│                                                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────┐  │
│  │   Web UI    │  │  Agent API  │  │   Execution Engine      │  │
│  │  (static)   │  │  /execute   │  │   Worker pool           │  │
│  │  /ui/*      │  │  /exec/{id} │  │   Sandboxed Python      │  │
│  │             │  │  /skill.md  │  │   Secret injection      │  │
│  └─────────────┘  └─────────────┘  └─────────────────────────┘  │
│                                                                  │
│  ┌─────────────────────────────────────────────────────────────┐ │
│  │                    SQLite Database                           │ │
│  │  credentials (encrypted) | profiles | executions | stats    │ │
│  └─────────────────────────────────────────────────────────────┘ │
└──────────────────────────────────────────────────────────────────┘
                   │
                   │ Outbound HTTP (allowlisted hosts only)
                   ▼
            ┌──────────────┐
            │ External APIs │
            │ (Oracle, etc) │
            └──────────────┘
```

---

## Credential & Profile System

### Credentials (Global Store)

Credentials are shared, user-managed secrets. They exist independently of profiles.

| Property | Description |
|----------|-------------|
| **Name** | Unique key name (e.g., `SIMPHONY_API_KEY`) |
| **Value** | Encrypted at rest, only decrypted at execution time |
| **Description** | What this credential is for |

- **Only the user** can create, edit, or delete credentials (via web UI)
- Agents **never** see credential values — only key names
- Updating a credential value propagates to **all profiles** that reference it (rotate once, done)

### Profiles

A **profile** is scoped access to credentials. Agents create profiles, users fill in values and lock them.

| Property | Description |
|----------|-------------|
| **ID** | `ark_` + random string (e.g., `ark_7f3x9kw2m4p`) |
| **Auth** | The profile ID itself acts as the API authentication token |
| **State** | `unlocked` → `locked` (one-way) |
| **Keys** | References to credentials (names only, never values) |
| **Expiration** | Optional date after which the profile auto-revokes |
| **Revocable** | Can be instantly revoked from the web UI |

### Profile States: Unlocked → Locked

**Unlocked** (setup phase — agent and user collaborate):
- Agent or user can **add/remove key references**
- User can **fill in credential values** for referenced keys
- Profile **cannot be used for execution**
- Agent can read: key names, descriptions, `value_exists` flags

**Locked** (production — user activates):
- **No structural changes** — keys cannot be added or removed
- User can still **update credential values** (propagates to all profiles using that credential)
- Profile **can be used for execution**
- User can revoke or set expiration

Keys can ONLY be added when the profile is unlocked. This applies to both agents and users.

### Why This Model?

- **Agent never sees credentials** — only opaque `ark_` IDs and key names
- **Agent drives setup** — creates profile, declares what keys it needs, describes each one
- **User controls secrets** — fills in values, reviews, locks when ready
- **Shared credentials** — rotate a key once, every profile gets it
- **Clear handoff** — unlocked = still setting up, locked = ready for production
- **Auditable** — every execution tied to a specific profile

### Agent API for Profiles

#### Create Profile
```
POST /profiles
{
  "description": "Oracle reporting — read only"
}

→ 201 Created
{
  "profile_id": "ark_7f3x9kw2m4p",
  "description": "Oracle reporting — read only",
  "locked": false,
  "keys": []
}
```

#### Add Keys (unlocked only)
```
POST /profiles/ark_7f3x9kw2m4p/keys
{
  "keys": [
    {"name": "SIMPHONY_API_KEY", "description": "Simphony REST API key"},
    {"name": "DB_HOST", "description": "Oracle DB hostname"}
  ]
}

→ 200 OK
```

#### Read Profile
```
GET /profiles/ark_7f3x9kw2m4p

→ 200 OK
{
  "profile_id": "ark_7f3x9kw2m4p",
  "description": "Oracle reporting — read only",
  "locked": false,
  "keys": [
    {"name": "SIMPHONY_API_KEY", "description": "Simphony REST API key", "value_exists": true},
    {"name": "DB_HOST", "description": "Oracle DB hostname", "value_exists": false}
  ]
}
```

#### Profile Lifecycle

```
Agent creates profile (unlocked)
  → Agent adds keys with descriptions
  → Agent tells user: "Open Airlock, fill in 3 values, then lock the profile"

User opens web UI
  → Sees requested keys with agent's descriptions
  → Fills in values (creates or links existing credentials)
  → Reviews everything
  → Hits Lock

Agent polls profile
  → Sees locked: true, all value_exists: true
  → Starts executing code
```

#### Credential Sharing Example

```
Credentials (global)
├── SIMPHONY_API_KEY = ••••••••
├── OPERA_API_KEY = ••••••••
└── DB_HOST = oracle.prod.local

Profile "Oracle Reporting" (locked)        Profile "Oracle Admin" (locked)
├── SIMPHONY_API_KEY → ✅                  ├── SIMPHONY_API_KEY → ✅  (same credential)
└── DB_HOST → ✅                           ├── OPERA_API_KEY → ✅
                                           └── DB_HOST → ✅          (same credential)

User rotates SIMPHONY_API_KEY once → both profiles get the new value
```

---

## Web UI

Airlock ships with a web UI baked into the Docker image. When the user deploys the container and opens `http://<host>:9090` in a browser, they get a management interface.

### First Boot

On first boot, Airlock generates an admin token and prints it to the container console:

```
╔══════════════════════════════════════════════════╗
║  Airlock admin token: atk_8f2k4m9x...           ║
║  Open http://localhost:9090 to configure         ║
╚══════════════════════════════════════════════════╝
```

### UI Sections

#### Credentials
- Add/edit/delete API credentials
- Credentials stored **encrypted** in SQLite
- Each credential has a name (e.g., `SIMPHONY_API_KEY`) and value
- Optional metadata: description, associated service/host

#### Profiles
- Create profiles with unique `ark_` IDs
- For each profile, select which credentials are visible to scripts
- Set optional expiration date (auto-revoke after date)
- Revoke/delete profiles at any time
- Copy profile ID to clipboard for sharing with agents

#### Execution History
- Table of all executions: profile, timestamp, status, duration
- Click to expand: see script code, stdout, result
- Filter by profile, status, date range

#### Stats Dashboard
- Executions per profile (chart)
- Error rates
- Average execution duration
- Active profiles count

---

## Two-Layer SKILL.md

SKILL.md is the mechanism for agent self-onboarding.

### Static SKILL.md (GitHub / airlock.sh)

Lives at `https://airlock.sh/skill.md` and in the repository root. Any agent can read this before Airlock is even deployed. Contains:

- What Airlock is
- How to deploy it (Docker command, cloud one-click)
- API reference (endpoints, request/response formats)
- SDK reference (what functions are available inside scripts)

### Dynamic `GET /skill.md` (Running Instance)

Served by the running Airlock instance at `GET /skill.md`. Returns instance-specific information:

- Instance URL
- Available profiles (ID + description + expiry)
- Which credentials each profile has access to (names only, never values)
- SDK reference
- Example code snippets tailored to available credentials

### Self-Onboarding Flow

```
Agent reads static SKILL.md from GitHub
  → Learns what Airlock is and how the API works
  → Generates deploy instructions for user

User deploys Airlock
  → docker run -p 9090:9090 ghcr.io/computclaw/airlock
  → Opens web UI, adds credentials, creates profiles

Agent reads dynamic GET /skill.md from running instance
  → Discovers available profiles and their capabilities
  → Self-onboards without further user intervention

Agent starts executing code
  → POST /execute {profile_id: "ark_...", script: "..."}
```

---

## Distribution & Deployment

### Single Container

Everything runs in one Docker container:

```bash
docker run -p 9090:9090 ghcr.io/computclaw/airlock:latest
```

- **Image**: `ghcr.io/computclaw/airlock:latest`
- **Port**: 9090 (web UI + agent API on the same port)
- **State**: SQLite database stored in a Docker volume
- **No external dependencies**

### What's Inside

```
Docker Container
├── FastAPI server on :9090
│   ├── /ui/*          → Web UI (static files)
│   ├── /execute       → Agent API
│   ├── /executions/*  → Agent API
│   ├── /skill.md      → Dynamic skill document
│   └── /health        → Health check
├── Execution engine
│   ├── Worker pool (sandboxed Python execution)
│   └── Secret injection + output sanitization
├── SQLite database
│   ├── credentials (encrypted)
│   ├── profiles
│   ├── executions (history)
│   └── stats
└── Web UI static assets
```

### Persistence

Mount a volume for the SQLite database:

```bash
docker run -p 9090:9090 -v airlock-data:/data ghcr.io/computclaw/airlock:latest
```

### Roadmap

- **v1**: Local network only — deploy on your LAN or localhost
- **v2**: Optional tunnel integration (ngrok/bore/cloudflare) — one toggle in the web UI to expose publicly

---

## Polling-Based Agent API

### Why Polling (Not Callbacks)?

- **No open ports needed** on the agent side
- **Works behind NAT**, firewalls, anywhere
- **No webhook infrastructure** to maintain
- **Simple**: agent just polls until done
- **LLM integration** fits naturally — `awaiting_llm` is just another status

### Execution Statuses

| Status | Meaning |
|--------|---------|
| `pending` | Queued, waiting for idle worker |
| `running` | Code is executing |
| `awaiting_llm` | Script called `llm.complete()`, waiting for agent to provide LLM response |
| `completed` | Finished successfully |
| `error` | Execution failed (exception, invalid code, etc.) |
| `timeout` | Exceeded time limit |

### API Endpoints

#### `POST /execute`

Submit code for execution. Authenticated by profile ID. Profile must be **locked**.

```
Request:
{
  "profile_id": "ark_7f3x9kw2m4p",
  "script": "import httpx\ndata = httpx.get(settings.get('API_URL'))...",
  "timeout": 60
}

Response: 202 Accepted
{
  "execution_id": "exec_a1b2c3d4",
  "poll_url": "https://airlock.example.com/executions/exec_a1b2c3d4",
  "status": "pending"
}
```

#### `GET /executions/{id}`

Poll for execution status and results.

```
Response (running):
{
  "execution_id": "exec_a1b2c3d4",
  "status": "running"
}

Response (awaiting LLM):
{
  "execution_id": "exec_a1b2c3d4",
  "status": "awaiting_llm",
  "llm_request": {
    "prompt": "Summarize this revenue data: ...",
    "model": "claude-sonnet"
  }
}

Response (completed):
{
  "execution_id": "exec_a1b2c3d4",
  "status": "completed",
  "result": { ... },
  "stdout": "...",
  "stderr": "...",
  "execution_time_ms": 1234
}

Response (error):
{
  "execution_id": "exec_a1b2c3d4",
  "status": "error",
  "error": "NameError: name 'foo' is not defined",
  "stdout": "...",
  "stderr": "...",
  "execution_time_ms": 89
}
```

#### `POST /executions/{id}/respond`

Provide an LLM response to a paused execution.

```
Request:
{
  "response": "Based on the revenue data, Q4 showed a 15% increase..."
}

Response: 200 OK
{
  "execution_id": "exec_a1b2c3d4",
  "status": "running"
}
```

#### `GET /skill.md`

Returns the dynamic skill document for agent self-onboarding. See [Two-Layer SKILL.md](#two-layer-skillmd).

#### `GET /health`

```
Response: 200 OK
{
  "status": "ok"
}
```

---

## LLM Integration via Pause/Resume

### Design Principle

Airlock holds **zero** LLM credentials. It is purely an execution service. The AI/non-deterministic part stays entirely on the agent side.

### How It Works

```
┌─────────┐         ┌──────────┐         ┌──────────┐
│  Agent   │         │ Airlock  │         │  Worker  │
│          │         │   API    │         │          │
│ POST     │────────▶│          │────────▶│ run code │
│ /execute │         │          │         │          │
│          │         │          │         │ ...      │
│          │         │          │◀────────│ llm.     │
│          │         │          │ pause   │ complete()│
│          │         │  status: │         │          │
│ GET      │────────▶│  await_  │         │ (blocked)│
│ /exec/id │◀────────│  llm     │         │          │
│          │         │          │         │          │
│ run LLM  │         │          │         │          │
│ locally  │         │          │         │          │
│          │         │          │         │          │
│ POST     │────────▶│          │────────▶│ resume   │
│ /respond │         │          │         │          │
│          │         │          │◀────────│ done     │
│ GET      │────────▶│ status:  │         │          │
│ /exec/id │◀────────│ completed│         │          │
└─────────┘         └──────────┘         └──────────┘
```

1. Script calls `llm.complete(prompt, model)`
2. Worker pauses execution, returns `{status: "awaiting_llm", prompt: "...", model: "..."}`
3. Airlock API stores the LLM request and updates execution status
4. Agent polls, sees `awaiting_llm`, reads the prompt
5. Agent runs the prompt through its own LLM (agent-side, with agent's own credentials)
6. Agent POSTs the response to `/executions/{id}/respond`
7. Airlock forwards the response to the worker
8. Worker resumes execution with the LLM response
9. Script continues — e.g., formatting the response into a report

### Why This Pattern?

- **No API keys in Airlock**: The execution environment never needs LLM credentials
- **Agent controls the model**: Agent can use whatever model, provider, or parameters it wants
- **Deterministic data + LLM presentation**: The script computes all the numbers deterministically, then optionally asks the LLM to write a narrative around them
- **Auditable**: The exact LLM prompt and response are visible in the execution record

---

## Script SDK

These functions are available to scripts running inside workers:

### `settings.get(key) → str`

Get a setting value. Credentials from the profile are injected and accessible by their key name. The script never sees raw values in env vars — they're resolved transparently.

### `settings.keys() → list[str]`

List all available setting keys for the current profile.

### `llm.complete(prompt, model="default") → str`

Pause execution and request an LLM completion from the agent. The execution status changes to `awaiting_llm`. When the agent provides a response via `/executions/{id}/respond`, execution resumes and this function returns the LLM's response.

**Use sparingly.** Only for presentation — summaries, narratives, insights. Never for data computation.

### `set_result(data)`

Set the structured return value of the script. `data` can be any JSON-serializable value. This is what appears in the `result` field of the completed execution response.

---

## Security Model

### Layer 1: Profile-Based Access Control

- Agents authenticate with opaque profile IDs (`ark_...`)
- Each profile grants access to a specific set of credentials
- Profiles can expire automatically
- Profiles are instantly revocable
- No credential values ever transmitted to agents

### Layer 2: Credential Encryption

- Credentials stored encrypted in SQLite
- Decrypted only at execution time, injected into worker environment
- Encryption key derived from instance secret (generated at first boot)

### Layer 3: Output Sanitization

All output is scanned before being returned to the agent:
- Exact-match against known credential values
- Common patterns: API keys, bearer tokens, connection strings
- Matches replaced with `[REDACTED...last4]` (last 4 chars preserved for debugging)
- Applied to: stdout, stderr, result data, error messages

### Layer 4: Network Isolation

- Each profile can declare an **allowlist** of hosts the code can reach
- Workers are network-isolated with rules enforcing the allowlist
- DNS resolution only for allowlisted hosts
- No "phone home" — code can't exfiltrate data to arbitrary endpoints

### Layer 5: Execution Sandboxing

- Workers run as **non-root** user
- Resource limits: memory cap, CPU cap, execution timeout
- Read-only filesystem (except /tmp)
- `--no-new-privileges` security option

### Security Boundary Summary

```
┌─────────────────────────────────────────────────────┐
│                    Agent                             │
│  • Sees only opaque profile IDs (ark_...)           │
│  • Never sees credential values                     │
│  • Receives only sanitized output                   │
│  • Owns LLM credentials (not Airlock)               │
├─────────────────────────────────────────────────────┤
│                  Airlock Server                      │
│  • Serves web UI for credential/profile management  │
│  • Routes execution requests to workers             │
│  • Resolves profiles → credentials at runtime       │
│  • Sanitizes all output before return               │
│  • Stores credentials encrypted                     │
├─────────────────────────────────────────────────────┤
│              Execution Environment                   │
│  • Credentials injected at runtime                  │
│  • Allowlisted network only                         │
│  • Non-root, resource-limited                       │
│  • Sandboxed from host system                       │
└─────────────────────────────────────────────────────┘
```

---

## Data Flow: Complete Execution

```
Agent                    Airlock Server             Worker              External API
  │                          │                         │                       │
  │ POST /execute            │                         │                       │
  │ {profile_id: "ark_...", │                         │                       │
  │  script: "..."}          │                         │                       │
  │─────────────────────────▶│                         │                       │
  │                          │ resolve profile          │                       │
  │                          │ → credentials: [A, B]    │                       │
  │                          │                         │                       │
  │                          │ inject creds → execute   │                       │
  │◀─────────────────────────│────────────────────────▶│                       │
  │ 202 {execution_id}      │                         │                       │
  │                          │                         │ httpx.get(API_URL)     │
  │                          │                         │──────────────────────▶│
  │                          │                         │◀──────────────────────│
  │                          │                         │ data                   │
  │ GET /executions/{id}     │                         │                       │
  │─────────────────────────▶│                         │ llm.complete(prompt)   │
  │◀─────────────────────────│◀────────────────────────│ (paused)              │
  │ {status: awaiting_llm,   │                         │                       │
  │  prompt: "..."}          │                         │                       │
  │                          │                         │                       │
  │ [agent runs LLM]         │                         │                       │
  │                          │                         │                       │
  │ POST /executions/{id}/   │                         │                       │
  │   respond {response}     │                         │                       │
  │─────────────────────────▶│────────────────────────▶│ (resumed)             │
  │                          │                         │                       │
  │                          │                         │ set_result(report)     │
  │                          │◀────────────────────────│ done                  │
  │                          │ sanitize output          │                       │
  │ GET /executions/{id}     │                         │                       │
  │─────────────────────────▶│                         │                       │
  │◀─────────────────────────│                         │                       │
  │ {status: completed,      │                         │                       │
  │  result: report}         │                         │                       │
  │                          │                         │                       │
```

---

## Deployment & Migration

### Zero-Console Deployment

Getting started should **never** require a terminal. Three paths to deployment:

#### 1. One-Click Cloud Deploy

Deploy buttons for major platforms — user clicks, fills in app name, done:

- **Render**: `render.yaml` blueprint in repo → "Deploy to Render" button
- **Railway**: `railway.toml` → "Deploy on Railway" button
- **Fly.io**: `fly.toml` → `flyctl deploy` (or agent-driven via Fly MCP)

Each generates a public URL. User opens it, lands on the web UI, starts adding credentials.

#### 2. Agent-Driven Deployment

The agent deploys Airlock on the user's behalf using platform MCPs:

```
Agent reads static SKILL.md from GitHub
  → Sees deployment instructions per platform
  → Uses Render MCP / Railway API / Fly CLI to create app
  → Gets public URL back
  → Tells user: "Airlock is live at https://your-app.onrender.com — open it to add your credentials"
  → Reads dynamic GET /skill.md from running instance
  → Self-onboards with available profiles
```

The static SKILL.md includes platform-specific deployment payloads (render.yaml, Dockerfile reference, env vars) so agents can programmatically deploy without human intervention.

#### 3. Docker (for power users)

```bash
docker run -p 9090:9090 -v airlock-data:/data ghcr.io/computclaw/airlock:latest
```

Still supported, still the simplest self-hosted option.

### Database Export / Import

The entire Airlock state lives in one SQLite file. Migration between hosts is a first-class feature:

#### Export (Web UI only)

Settings → Export → enter passphrase → download `.airlock` file

- Dumps the full SQLite database, **encrypted** with AES-256 using the passphrase
- Optional: selective export (specific profiles only)
- **No API endpoint** — export is a human action, not an agent action

#### Import (Web UI only)

Settings → Import → upload `.airlock` file → enter passphrase → preview → confirm

- Preview mode: shows what will be imported (profiles, credentials, history) before committing
- Merge strategy: skip duplicates, or overwrite — user chooses
- Restores profiles, credentials, execution history
- **No API endpoint** — credentials should never flow through agent-accessible routes

#### Why UI-Only?

Export/import involves the raw credential database. This is the one thing agents should **never** be able to trigger — even with admin tokens. Keeping it browser-only means a human is always in the loop when secrets move between instances.

#### Migration Flow

```
Local Docker instance
  → Web UI: Settings → Export → enter passphrase → download .airlock file

New cloud instance (Render, Railway, etc.)
  → Web UI: Settings → Import → upload .airlock file → enter passphrase → preview → confirm
  → All profiles, credentials, and history restored
  → Agents using ark_ profile IDs continue working with zero changes
```

#### Auto-Backup

- Optional scheduled encrypted snapshots to a mounted volume or S3-compatible storage
- Configurable retention (keep last N backups)
- One toggle in Settings

---

## Future Considerations

- **Multi-language workers**: Node.js, SQL execution
- **Code caching**: Hash code, skip re-execution for identical requests
- **Tunnel integration (v2)**: ngrok/bore/cloudflare — one toggle in UI for public access
- **Worker auto-scaling**: Scale workers based on queue depth
- **Health checks**: Periodic liveness probes on workers, auto-restart unhealthy ones
- **Profile templates**: Pre-built profile configurations for common use cases
