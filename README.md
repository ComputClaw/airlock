# Airlock

**A trust boundary between AI agents and infrastructure.**

**Website:** [airlock.sh](https://airlock.sh)

## The Problem

AI agents are great at reasoning. They're terrible at holding secrets and doing math.

**No serious company gives production credentials to an LLM.** Your Stripe API key, your database connection string, your Oracle auth token â€” flowing through model context windows, sitting in plaintext logs, one prompt injection away from exfiltration. Compliance teams shut this down on sight, and they're right to.

**Non-deterministic workflows don't work in business.** Your CFO asks "why is this number different from yesterday?" and you can't say "the AI felt different today." Reports, pipelines, monitoring â€” they need to produce the same output given the same input. Every time.

These aren't edge cases. They're the two walls that every AI-in-the-enterprise project hits.

## The Solution

**Credentials stay in a trusted environment the agent can't see.** The agent gets an opaque profile key. Airlock resolves that to real credentials at runtime, injects them into the execution environment, and scrubs them from the output. The agent never sees, touches, or transmits a single secret.

**Execution is deterministic Python â€” not an LLM guessing its way through API calls.** The agent writes real code. `httpx.get()`, `pandas.DataFrame()`, actual Python that does exactly what it says. Same code, same data, same numbers.

## Quick Start

```bash
docker run -p 9090:9090 ghcr.io/computclaw/airlock:latest
```

Open `http://localhost:9090` in your browser. That's it.

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DEPLOY                                              â”‚
â”‚     User runs Docker container, opens web UI            â”‚
â”‚     Sets admin password on first visit                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. CREDENTIALS                                         â”‚
â”‚     Agent creates credential slots (name + description) â”‚
â”‚     User fills in actual values via web UI              â”‚
â”‚     All values encrypted at rest (AES-256-GCM)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. PROFILES                                            â”‚
â”‚     Agent or user creates a profile                     â”‚
â”‚     Selects which credentials the profile can access    â”‚
â”‚     User locks the profile â†’ generates ark_ID:SECRET    â”‚
â”‚     Key shown once, copy it, won't be shown again       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. EXECUTE                                             â”‚
â”‚     Agent sends code + HMAC hash + Bearer auth          â”‚
â”‚     Airlock verifies identity + code integrity          â”‚
â”‚     Injects credentials into sandboxed Python worker    â”‚
â”‚     Returns sanitized results (secrets redacted)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Credentials

Agents and users collaborate to manage credentials:

- **Agent creates slots** â€” defines what credentials are needed (name + description), e.g., "Stripe API Key", "Database URL"
- **User fills values** â€” enters actual secrets via the web UI (never through the API)
- **Encrypted at rest** â€” AES-256-GCM with a master key stored in the persistent volume
- **Agent never sees values** â€” the API returns `value_exists: true/false`, never the actual secret
- **Export/import** â€” migrate your entire Airlock state between hosts, encrypted with a user-chosen passphrase

## Profiles

A profile is scoped, authenticated access to a set of credentials:

- **Two-part key:** `ark_ID:SECRET` â€” generated when the user locks the profile
- **Auth flow:** Agent sends `Authorization: Bearer ark_ID` + `HMAC-SHA256(secret, script)` as a hash in the request body
- **Code integrity:** The HMAC proves the script hasn't been tampered with in transit
- **Lifecycle:** unlocked (configuring) â†’ locked (production-ready) â†’ revocable at any time
- **Expiration:** optional expiry date, auto-revokes after
- **Key regeneration:** rotate the key without recreating the profile
- **Scoped access:** each profile only exposes selected credentials

```
Profile lifecycle:

  CREATE â†’ add credentials â†’ LOCK â†’ execute â†’ REVOKE
                                â†‘         â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              (regenerate key)
```

## Deployment

Single Docker image. No external dependencies.

```bash
# Standalone
docker run -d -p 9090:9090 -v airlock_data:/data ghcr.io/computclaw/airlock:latest

# Docker Compose
docker compose up -d
```

The `-v airlock_data:/data` volume persists credentials, profiles, execution history, and the encryption master key across restarts.

### Cloud Deploy

One-click deploy to:

- **Render** â€” persistent disk for `/data`
- **Railway** â€” volume mount for `/data`
- **Fly.io** â€” volume for `/data`

_(Deploy buttons coming soon)_

### Requirements

Agents can declare Python package requirements:

```
POST /requirements
{"packages": ["httpx", "pandas", "openpyxl"]}
```

Packages are `pip install`'d in the running container and persisted in the database â€” automatically reinstalled on restart.

## Agent Integration

### Self-Onboarding

Airlock is designed so agents can discover and onboard themselves:

1. **Static SKILL.md** (GitHub / airlock.sh) â€” agent learns what Airlock is and how the API works
2. **User deploys** â€” `docker run` or one-click cloud
3. **Dynamic `GET /skill.md`** (running instance) â€” returns available profiles, SDK reference, instance URL
4. **Agent starts executing** â€” `POST /execute` with profile auth

### API Surface

```
# Agent endpoints (no admin auth needed)
GET  /skill.md                        â†’ Dynamic skill doc for self-onboarding
GET  /credentials                     â†’ List credential slots (no values)
POST /credentials                     â†’ Create credential slot
GET  /profiles                        â†’ List available profiles
GET  /profiles/{id}                   â†’ Profile details
POST /profiles                        â†’ Create a profile
POST /profiles/{id}/credentials       â†’ Add credential to profile
DELETE /profiles/{id}/credentials     â†’ Remove credential from profile
POST /requirements                    â†’ Install Python packages
GET  /requirements                    â†’ List installed packages
POST /execute                         â†’ Execute code (Bearer auth + HMAC)
GET  /executions/{id}                 â†’ Poll for results
POST /executions/{id}/respond         â†’ Resume LLM pause

# Admin endpoints (session token from web UI login)
POST /api/admin/profiles/{id}/lock    â†’ Lock profile, returns ark_ID:SECRET
POST /api/admin/profiles/{id}/revoke  â†’ Revoke profile
POST /api/admin/profiles/{id}/regenerate-key â†’ Rotate key
```

### LLM Pause/Resume

Scripts can call `llm.complete(prompt)` to pause execution and ask the agent for LLM reasoning:

```python
# Inside a script running in Airlock
result = llm.complete("Summarize these Q4 numbers: " + json.dumps(data))
```

The execution pauses, the agent sees `{status: "awaiting_llm", prompt: "..."}`, runs the LLM, and posts the response back. Deterministic data processing + LLM interpretation, cleanly separated.

## Security Model

- **Credentials never leave Airlock** â€” agents only see opaque profile keys
- **HMAC code integrity** â€” `HMAC-SHA256(secret, script)` proves code wasn't tampered with
- **Encrypted storage** â€” AES-256-GCM, master key in persistent volume
- **Output sanitization** â€” all output scanned for secrets before return
- **Profile scoping** â€” each profile only exposes selected credentials
- **Expiration & revocation** â€” time-limited access, instantly revocable
- **Sandboxed execution** â€” non-root, resource-limited, isolated Python worker
- **No TLS in v1** â€” rely on infrastructure (Render/Railway/Fly/nginx). Airlock focuses on what runs above the transport layer.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Container        â”‚
â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Svelte   â”‚   â”‚  Python   â”‚  â”‚
â”‚  â”‚ Web UI   â”‚   â”‚  FastAPI  â”‚  â”‚
â”‚  â”‚ (static) â”‚   â”‚  Backend  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚               â”‚         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚               â”‚                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚         â”‚   SQLite    â”‚          â”‚
â”‚         â”‚  (encrypted â”‚          â”‚
â”‚         â”‚   values)   â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚               â”‚                 â”‚
â”‚         /data volume            â”‚
â”‚  (credentials, profiles,        â”‚
â”‚   master key, history)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Single Docker image, multi-stage build: Svelte frontend + Python FastAPI backend. Everything in one container.

## Status

ğŸš§ **Under active development.**

- âœ… Phase 1: Foundation (API, execution engine, web UI)
- âœ… Phase 2: Docker execution (sandboxed Python workers)
- âœ… Phase 3: Credential management (encrypted storage, agent/user collaboration)
- ğŸ”¨ Phase 4: Profile system (two-part keys, HMAC auth, lock/revoke lifecycle)

Built by [Martin Bundgaard](https://github.com/ComputClaw) and [Comput](https://comput.sh).

## Docs

- [Architecture](docs/architecture.md) â€” full system design
- [Agent Guide](docs/agent-guide.md) â€” 8-step workflow from discovery to execution
- [Specs](specs/) â€” detailed implementation specs for each phase
